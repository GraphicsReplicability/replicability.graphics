[
    {
        "Variant name": "Ubuntu 20.04 LTS",
        "Reviewer name": "David Coeurjolly <david.coeurjolly@liris.cnrs.fr>",
        "Is master variant (boolean)": true,
        "Is variant deprecated (boolean)": false,
        "Title": "Single-image SVBRDF capture with a rendering-aware deep network",
        "DOI": "10.1145/3197517.3201378",
        "Year": 2018,
        "ACM Keywords": [
            "Reflectance modeling",
            "Image processing"
        ],
        "Topic {Rendering, Animation and Simulation, Geometry, Images, Virtual Reality, Fabrication}": "Rendering",
        "Co-authors from academia (boolean)": true,
        "Co-authors from industry (boolean)": false,
        "ACM Open Access (boolean)": true,
        "PDF on the authors' webpage / institution (boolean)": true,
        "PDF URL": "https://www-sop.inria.fr/reves/Basilic/2018/DADDB18/Deep%20Material%20Acquisition%20Authors_version.pdf",
        "PDF on Arxiv or any openarchive initiatives (boolean)": false,
        "Arxiv/OAI page URL": "",
        "Project URL": "https://www-sop.inria.fr/reves/Basilic/2018/DADDB18/",
        "Code available (boolean)": true,
        "If code not available, pseudo-code available (boolean)": false,
        "If pseudo-code, could the paper be trivially implemented? {0..4}": "",
        "Code URL": "https://repo-sam.inria.fr/fungraph/deep-materials/",
        "Code URL2": "https://repo-sam.inria.fr/fungraph/deep-materials/InferenceCode_DeepMaterials.zip",
        "MD5 sum (for archives)": "2da19dfe747fdf1498be6a236a8a8b1b",
        "git/hg/svn commit hash or revision number": "",
        "MD5 sum (for archives) URL2": "",
        "git/hg/svn commit hash or revision number URL2": "",
        "Software Heritage permalink": "",
        
        "Software type {Code, Binary, Partial Code}": "Code",
        "Code License (if any)": "For research only, not for commercial use. Do not distribute. (The license is temporary)",
        "Are the code authors explicit? (boolean)": false,

        "Build/Configure mechanism": "N/A",
        "Dependencies": "tensorflow",
        
        "Does the software require paywall/proprietary software/material (boolean)?": false,
        "Does the code need data (not examples) (boolean)": true,
        "Nature of the data (pretrained model, LUT...)": "pretrained models",
        "License of the data": "For research only, not for commercial use. Do not distribute.",
        "Able to perform a replicability test (boolean)": false,
        "If not able to perform a test, was it due to missing hardware/software? (boolean)": false,
        
        "Documentation score {0=NA,1,2,3}": 1,
        "Dependencies score {0=NA, 1,2,3,4,5}": 5,
        "Build/configure score {0=NA, 1,2,3,4,5}": 0,
        "Fixing bugs score (if any) {0=NA, 1,2,3,4,5}": 3,
        "Replicate paper results score {0=NA, 1,2,3,4,5}": 0
        "Adaptability score to other contexts {0=NA, 1,2,3,4,5}": "",
        "Time spent for the test (code download to first successful run, [0,10], 10min slots, 100min max)": 4,
        "Operating system for the test": "macOS catalina",
        "Build instructions/comments": "Pretrained models are provided in the code archive. Results, datasets and supplemental materials are available on a second project page (https://team.inria.fr/graphdeco/projects/deep-materials/). No dependency issue (just tensorflow installed using conda, version 2.1, the authors do not give the exact tensorflow version they are using) but the runExampleTest.sh does not work directly (tensorflow API issues). After performing these edits:

148c148
<         resized_images = tf.image.resize(batch_input, [in_height * 2, in_width * 2], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)
---
>         resized_images = tf.image.resize_images(batch_input, [in_height * 2, in_width * 2], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)
248c248
<     image_string = tf.io.read_file(filename)
---
>     image_string = tf.read_file(filename)
294c294
<         r = tf.image.resize(r, [a.scale_size, a.scale_size], method=tf.image.ResizeMethod.AREA)
---
>         r = tf.image.resize_images(r, [a.scale_size, a.scale_size], method=tf.image.ResizeMethod.AREA)
382c382
<     return  (tf.math.log(tf.add(tensor,0.01)) - tf.math.log(0.01)) / (tf.math.log(1.01)-tf.math.log(0.01))
---
>     return  (tf.log(tf.add(tensor,0.01)) - tf.log(0.01)) / (tf.log(1.01)-tf.log(0.01))
616c616
<     tf.random.set_seed(a.seed)
---
>     tf.set_random_seed(a.seed)


I ended up with an issue I was not able to solve:

Traceback (most recent call last):
  File "material_net_test.py", line 752, in <module>
    main()
  File "material_net_test.py", line 644, in main
    examples = load_examples(a.input_dir, a.mode == "train")
  File "material_net_test.py", line 330, in load_examples
    iterator = batched_dataset.make_initializable_iterator()
AttributeError: 'BatchDataset' object has no attribute 'make_initializable_iterator'

Editing line 330 with 
    iterator = tf.compat.v1.data.make_initializable_iterator(batched_dataset)
does not help.

I was not able to create a conda env with a 1.7 or 1.8 tensorflow (which may correspond to the tensorflow the authors used) due to CUDA incompatibility issues.

",
        "Misc. comments": "",
        "Software language": "python"
    },
    {
        "Variant name": "macOS catalina",
        "Reviewer name": "David Coeurjolly <david.coeurjolly@liris.cnrs.fr>",
        "Is master variant (boolean)": true,
        "Is variant deprecated (boolean)": false,
        "Title": "Single-image SVBRDF capture with a rendering-aware deep network",
        "DOI": "10.1145/3197517.3201378",
        "Year": 2018,
        "ACM Keywords": [
            "Reflectance modeling",
            "Image processing"
        ],
        "Topic {Rendering, Animation and Simulation, Geometry, Images, Virtual Reality, Fabrication}": "Rendering",
        "Co-authors from academia (boolean)": true,
        "Co-authors from industry (boolean)": false,
        "ACM Open Access (boolean)": true,
        "PDF on the authors' webpage / institution (boolean)": true,
        "PDF URL": "https://www-sop.inria.fr/reves/Basilic/2018/DADDB18/Deep%20Material%20Acquisition%20Authors_version.pdf",
        "PDF on Arxiv or any openarchive initiatives (boolean)": false,
        "Arxiv/OAI page URL": "",
        "Project URL": "https://www-sop.inria.fr/reves/Basilic/2018/DADDB18/",
        "Code available (boolean)": true,
        "If code not available, pseudo-code available (boolean)": false,
        "If pseudo-code, could the paper be trivially implemented? {0..4}": "",
        "Code URL": "https://repo-sam.inria.fr/fungraph/deep-materials/",
        "Code URL2": "https://repo-sam.inria.fr/fungraph/deep-materials/InferenceCode_DeepMaterials.zip",
        "MD5 sum (for archives)": "2da19dfe747fdf1498be6a236a8a8b1b",
        "git/hg/svn commit hash or revision number": "",
        "MD5 sum (for archives) URL2": "",
        "git/hg/svn commit hash or revision number URL2": "",
        "Software Heritage permalink": "",
        
        "Software type {Code, Binary, Partial Code}": "Code",
        "Code License (if any)": "For research only, not for commercial use. Do not distribute. (The license is temporary)",
        "Are the code authors explicit? (boolean)": false,

        "Build/Configure mechanism": "N/A",
        "Dependencies": "tensorflow",
        
        "Does the software require paywall/proprietary software/material (boolean)?": false,
        "Does the code need data (not examples) (boolean)": true,
        "Nature of the data (pretrained model, LUT...)": "pretrained models",
        "License of the data": "For research only, not for commercial use. Do not distribute.",
        "Able to perform a replicability test (boolean)": false,
        "If not able to perform a test, was it due to missing hardware/software? (boolean)": false,
        
        "Documentation score {0=NA,1,2,3}": 1,
        "Dependencies score {0=NA, 1,2,3,4,5}": 5,
        "Build/configure score {0=NA, 1,2,3,4,5}": 0,
        "Fixing bugs score (if any) {0=NA, 1,2,3,4,5}": 1,
        "Replicate paper results score {0=NA, 1,2,3,4,5}": 0
        "Adaptability score to other contexts {0=NA, 1,2,3,4,5}": "",
        "Time spent for the test (code download to first successful run, [0,10], 10min slots, 100min max)": 2,
        "Operating system for the test": "macOS catalina",
        "Build instructions/comments": "Pretrained models are provided in the code archive. Results, datasets and supplemental materials are available on a second project page (https://team.inria.fr/graphdeco/projects/deep-materials/). No dependency issue (just tensorflow installed using pip, version 2.1.0, the authors do not give the exact tensorflow version they are using) but the runExampleTest.sh crashes on my system with the following error code (which I was not able to solve):

[libprotobuf ERROR google/protobuf/descriptor_database.cc:394] Invalid file descriptor data passed to EncodedDescriptorDatabase::Add().
[libprotobuf FATAL google/protobuf/descriptor.cc:1356] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
libc++abi.dylib: terminating with uncaught exception of type google::protobuf::FatalException: CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
./runExampleTest.sh: line 2: 25883 Abort trap: 6           python3 material_net_test.py --input_dir inputExamples/ --mode eval --output_dir examples_outputs --checkpoint . --imageFormat png --scale_size 256

",
        "Misc. comments": "",
        "Software language": "python"
    }
]
