[
    {
        "Variant name": "main",
        "Reviewer name": "Nicolas Bonneel <nicolas.bonneel@liris.cnrs.fr>",
        "Is master variant (boolean)": true,
        "Is variant deprecated (boolean)": false,
        "Title": "VisemeNet: Audio-Driven Animator-Centric Speech Animation",
        "DOI": "10.1145/3197517.3201292",
        "Year": 2018,
        "ACM Keywords": [
            "Machine learning algorithms",
            "Animation"
        ],
        "Topic {Rendering, Animation and Simulation, Geometry, Images, Virtual Reality, Fabrication}": "Animation and Simulation",
        "Co-authors from academia (boolean)": true,
        "Co-authors from industry (boolean)": false,
        "ACM Open Access (boolean)": false,
        "PDF on the authors' webpage / institution (boolean)": true,
        "PDF URL": "http://www.dgp.toronto.edu/~karan/papers/visemenetSIG18.pdf",
        "PDF on Arxiv or any openarchive initiatives (boolean)": true,
        "Arxiv/OAI page URL": "https://arxiv.org/abs/1805.09488",
        "Project URL": "https://people.umass.edu/~yangzhou/visemenet/",
        "Code available (boolean)": true,
        "If code not available, pseudo-code available (boolean)": false,
        "If pseudo-code, could the paper be trivially implemented? {0..4}": "",
        "Code URL": "https://github.com/yzhou359/VisemeNet_tensorflow",
        "Code URL2": "",
        "MD5 sum (for archives)": "",
        "git/hg/svn commit hash or revision number": "94c36dcd6f475ed493207891ec8f2822d0580a27",
        "MD5 sum (for archives) URL2": "",
        "git/hg/svn commit hash or revision number URL2": "",
        "Software Heritage permalink": "https://archive.softwareheritage.org/swh:1:rev:94c36dcd6f475ed493207891ec8f2822d0580a27;origin=https://github.com/yzhou359/VisemeNet_tensorflow/",
        "Software type {Code, Binary, Partial Code}": "Code",
        "Code License (if any)": "unspecified",
        "Are the code authors explicit? (boolean)": false,
        "Build/Configure mechanism": "Not applicable (python, Matlab..)",
        "Dependencies": "tensorflow / cudnn / numpy / scipy / matplotlib / python_speech_features / Maya",
        "Does the software require paywall/proprietary software/material (boolean)?": false,
        "Does the code need data (not examples) (boolean)": true,
        "Nature of the data (pretrained model, LUT...)": "Training data, Pre-trained models / Hardcoded data / lookup tables /...",
        "License of the data": "custom",
        "Able to perform a replicability test (boolean)": true,
        "If not able to perform a test, was it due to missing hardware/software? (boolean)": false,
        "Documentation score {0=NA,1,2,3}": 1,
        "Dependencies score {0=NA, 1,2,3,4,5}": 4,
        "Build/configure score {0=NA, 1,2,3,4,5}": 5,
        "Fixing bugs score (if any) {0=NA, 1,2,3,4,5}": 0,
        "Replicate paper results score {0=NA, 1,2,3,4,5}": 4,
        "Adaptability score to other contexts {0=NA, 1,2,3,4,5}": 5,
        "Time spent for the test (code download to first successful run, [0,10], 10min slots, 100min max)": 4,
        "Operating system for the test": "Windows",
        "Build instructions/comments": "Note that the VisemeNet code has strong requirements on software and library versions. The code does run on Python 3.5 but not on Python 3.6.5. Also, Python 3.5 now comes with a default scipy 1.4.0 which is not suitable, though an older scipy 1.1.0 works.\nI could test the prediction with the provided trained network on the single provided audio file, as well as the Maya script to use the results on a public face rig. This worked nicely.\nI did not test the training as data are only accessible upon (non-anonymous) request, and training instructions and scripts are not provided (although a non-standalone train_visemenet.py file is present, it does not run on its own).\n\n--alternative test on linux--\nI failed to have the tensorflow package within anaconda to work with libcudnn.so.8.0.",
        "Misc. comments": "",
        "Software language": "Python"
    }
]